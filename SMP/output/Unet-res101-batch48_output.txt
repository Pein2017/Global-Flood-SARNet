Downloaded and cached Unet model with resnet101 encoder.
Using NPU: npu:3 ...

TRAIN_CROP_SIZE = 256
TARGET_SIZE = 256
NUM_WORKERS = 4
PIN_MEMORY = False
BATCH_SIZE = 48
EPS = 1e-07
EXPERIMENT_NAME = 'Exp2-Unet-resnet101-b48'
ENCODER_NAME = 'resnet101'
MODEL_NAME = 'Unet'
ENCODER_WEIGHTS = 'imagenet'
IN_CHANNELS = 2
CLASSES = 2
PATIENCE = 6
N_EPOCHS = 200
LEARNING_RATE = 0.0001
EARLY_STOP_THRESHOLD = 20
EARLY_STOP_PATIENCE = 30

-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|Epoch: [1] Train - TotalT: 9.9 min, BatchT: 39.650s, DataT: 0.169s, Loss: 0.6958
/-\|/-\|/-\|/-\|/-\|/-\|/-\|/-\|/Epoch: [1] Val - TotalT: 15.3 min, Loss: 0.4462
Global IoU: 0.4888
Epoch: [2] Train - TotalT: 15.5 min, BatchT: 0.544s, DataT: 0.281s, Loss: 0.6006
Epoch: [2] Val - TotalT: 15.5 min, Loss: 0.3545
Global IoU: 0.5405
Epoch: [3] Train - TotalT: 15.6 min, BatchT: 0.524s, DataT: 0.261s, Loss: 0.5796
Epoch: [3] Val - TotalT: 15.7 min, Loss: 0.2575
Global IoU: 0.6768
Epoch: [4] Train - TotalT: 15.8 min, BatchT: 0.544s, DataT: 0.277s, Loss: 0.5429
Epoch: [4] Val - TotalT: 15.9 min, Loss: 0.2530
Global IoU: 0.7074
Epoch: [5] Train - TotalT: 16.0 min, BatchT: 0.545s, DataT: 0.279s, Loss: 0.5287
Epoch: [5] Val - TotalT: 16.0 min, Loss: 0.3557
Global IoU: 0.6512
Epoch: [6] Train - TotalT: 16.2 min, BatchT: 0.534s, DataT: 0.270s, Loss: 0.5147
Epoch: [6] Val - TotalT: 16.2 min, Loss: 0.2832
Global IoU: 0.7199
Epoch: [7] Train - TotalT: 16.3 min, BatchT: 0.541s, DataT: 0.277s, Loss: 0.5238
Epoch: [7] Val - TotalT: 16.4 min, Loss: 0.2109
Global IoU: 0.7337
Epoch: [8] Train - TotalT: 16.5 min, BatchT: 0.526s, DataT: 0.262s, Loss: 0.4741
Epoch: [8] Val - TotalT: 16.6 min, Loss: 0.2385
Global IoU: 0.6808
Epoch: [9] Train - TotalT: 16.7 min, BatchT: 0.564s, DataT: 0.299s, Loss: 0.4800
Epoch: [9] Val - TotalT: 16.8 min, Loss: 0.2388
Global IoU: 0.7197
Epoch: [10] Train - TotalT: 16.9 min, BatchT: 0.548s, DataT: 0.284s, Loss: 0.4638
Epoch: [10] Val - TotalT: 16.9 min, Loss: 0.1915
Global IoU: 0.7563
Epoch: [11] Train - TotalT: 17.1 min, BatchT: 0.536s, DataT: 0.271s, Loss: 0.4489
Epoch: [11] Val - TotalT: 17.1 min, Loss: 0.2229
Global IoU: 0.7123
Epoch: [12] Train - TotalT: 17.2 min, BatchT: 0.526s, DataT: 0.262s, Loss: 0.4781
Epoch: [12] Val - TotalT: 17.3 min, Loss: 0.2998
Global IoU: 0.5588
Epoch: [13] Train - TotalT: 17.4 min, BatchT: 0.543s, DataT: 0.279s, Loss: 0.4626
Epoch: [13] Val - TotalT: 17.5 min, Loss: 0.1810
Global IoU: 0.7341
Epoch: [14] Train - TotalT: 17.6 min, BatchT: 0.562s, DataT: 0.298s, Loss: 0.4535
Epoch: [14] Val - TotalT: 17.7 min, Loss: 0.1805
Global IoU: 0.7265
Epoch: [15] Train - TotalT: 17.8 min, BatchT: 0.539s, DataT: 0.275s, Loss: 0.4625
Epoch: [15] Val - TotalT: 17.8 min, Loss: 0.1821
Global IoU: 0.7447
Epoch: [16] Train - TotalT: 18.0 min, BatchT: 0.525s, DataT: 0.260s, Loss: 0.4246
Epoch: [16] Val - TotalT: 18.0 min, Loss: 0.1522
Global IoU: 0.7754
Epoch: [17] Train - TotalT: 18.2 min, BatchT: 0.562s, DataT: 0.296s, Loss: 0.4432
Epoch: [17] Val - TotalT: 18.2 min, Loss: 0.1515
Global IoU: 0.7669
Epoch: [18] Train - TotalT: 18.3 min, BatchT: 0.569s, DataT: 0.304s, Loss: 0.4326
Epoch: [18] Val - TotalT: 18.4 min, Loss: 0.1612
Global IoU: 0.7719
Epoch: [19] Train - TotalT: 18.5 min, BatchT: 0.537s, DataT: 0.273s, Loss: 0.4333
Epoch: [19] Val - TotalT: 18.6 min, Loss: 0.1977
Global IoU: 0.7430
Epoch: [20] Train - TotalT: 18.7 min, BatchT: 0.554s, DataT: 0.288s, Loss: 0.4302
Epoch: [20] Val - TotalT: 18.8 min, Loss: 0.2466
Global IoU: 0.6570
Epoch: [21] Train - TotalT: 18.9 min, BatchT: 0.532s, DataT: 0.268s, Loss: 0.4298
Epoch: [21] Val - TotalT: 18.9 min, Loss: 0.1455
Global IoU: 0.7803
Epoch: [22] Train - TotalT: 19.1 min, BatchT: 0.541s, DataT: 0.278s, Loss: 0.4444
Epoch: [22] Val - TotalT: 19.1 min, Loss: 0.1743
Global IoU: 0.7465
Epoch: [23] Train - TotalT: 19.2 min, BatchT: 0.532s, DataT: 0.268s, Loss: 0.4435
Epoch: [23] Val - TotalT: 19.3 min, Loss: 0.2767
Global IoU: 0.5924
Epoch: [24] Train - TotalT: 19.4 min, BatchT: 0.537s, DataT: 0.273s, Loss: 0.4142
Epoch: [24] Val - TotalT: 19.5 min, Loss: 0.2438
Global IoU: 0.6807
Epoch: [25] Train - TotalT: 19.6 min, BatchT: 0.555s, DataT: 0.291s, Loss: 0.4408
Epoch: [25] Val - TotalT: 19.7 min, Loss: 0.2886
Global IoU: 0.7309
Epoch: [26] Train - TotalT: 19.8 min, BatchT: 0.558s, DataT: 0.294s, Loss: 0.4140
Epoch: [26] Val - TotalT: 19.8 min, Loss: 0.2335
Global IoU: 0.6990
Epoch: [27] Train - TotalT: 20.0 min, BatchT: 0.559s, DataT: 0.292s, Loss: 0.4328
Epoch: [27] Val - TotalT: 20.0 min, Loss: 0.1770
Global IoU: 0.7294
Epoch: [28] Train - TotalT: 20.2 min, BatchT: 0.558s, DataT: 0.292s, Loss: 0.4504
Epoch: [28] Val - TotalT: 20.2 min, Loss: 0.3557
Global IoU: 0.5064
Epoch: [29] Train - TotalT: 20.3 min, BatchT: 0.550s, DataT: 0.283s, Loss: 0.4256
Epoch: [29] Val - TotalT: 20.4 min, Loss: 0.2078
Global IoU: 0.7468
Epoch: [30] Train - TotalT: 20.5 min, BatchT: 0.539s, DataT: 0.273s, Loss: 0.4341
Epoch: [30] Val - TotalT: 20.6 min, Loss: 0.1619
Global IoU: 0.7649
Epoch: [31] Train - TotalT: 20.7 min, BatchT: 0.560s, DataT: 0.293s, Loss: 0.4361
Epoch: [31] Val - TotalT: 20.8 min, Loss: 0.1654
Global IoU: 0.7646
Epoch: [32] Train - TotalT: 20.9 min, BatchT: 0.542s, DataT: 0.277s, Loss: 0.4116
Epoch: [32] Val - TotalT: 20.9 min, Loss: 0.1607
Global IoU: 0.7630
Epoch: [33] Train - TotalT: 21.1 min, BatchT: 0.545s, DataT: 0.281s, Loss: 0.4106
Epoch: [33] Val - TotalT: 21.1 min, Loss: 0.1728
Global IoU: 0.7686
Epoch: [34] Train - TotalT: 21.3 min, BatchT: 0.559s, DataT: 0.295s, Loss: 0.4254
Epoch: [34] Val - TotalT: 21.3 min, Loss: 0.1515
Global IoU: 0.7699
Epoch: [35] Train - TotalT: 21.4 min, BatchT: 0.554s, DataT: 0.290s, Loss: 0.4378
Epoch: [35] Val - TotalT: 21.5 min, Loss: 0.1699
Global IoU: 0.7479
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Epoch: [36] Train - TotalT: 21.6 min, BatchT: 0.563s, DataT: 0.300s, Loss: 0.4062
Epoch: [36] Val - TotalT: 21.7 min, Loss: 0.1865
Global IoU: 0.7542
Epoch: [37] Train - TotalT: 21.8 min, BatchT: 0.605s, DataT: 0.340s, Loss: 0.4196
Epoch: [37] Val - TotalT: 21.9 min, Loss: 0.1924
Global IoU: 0.7758
Epoch: [38] Train - TotalT: 22.0 min, BatchT: 0.604s, DataT: 0.339s, Loss: 0.4205
Epoch: [38] Val - TotalT: 22.1 min, Loss: 0.1991
Global IoU: 0.7801
Epoch: [39] Train - TotalT: 22.2 min, BatchT: 0.590s, DataT: 0.323s, Loss: 0.3883
Epoch: [39] Val - TotalT: 22.3 min, Loss: 0.1803
Global IoU: 0.7851
Epoch: [40] Train - TotalT: 22.4 min, BatchT: 0.590s, DataT: 0.325s, Loss: 0.4096
Epoch: [40] Val - TotalT: 22.5 min, Loss: 0.1833
Global IoU: 0.7891
Epoch: [41] Train - TotalT: 22.6 min, BatchT: 0.585s, DataT: 0.320s, Loss: 0.4145
Epoch: [41] Val - TotalT: 22.7 min, Loss: 0.1798
Global IoU: 0.7976
Epoch: [42] Train - TotalT: 22.8 min, BatchT: 0.573s, DataT: 0.308s, Loss: 0.3912
Epoch: [42] Val - TotalT: 22.9 min, Loss: 0.1730
Global IoU: 0.7956
Epoch 00022: reducing learning rate of group 0 to 1.0000e-06.
Epoch: [43] Train - TotalT: 23.0 min, BatchT: 0.578s, DataT: 0.311s, Loss: 0.4267
Epoch: [43] Val - TotalT: 23.1 min, Loss: 0.1765
Global IoU: 0.7954
Epoch: [44] Train - TotalT: 23.2 min, BatchT: 0.581s, DataT: 0.315s, Loss: 0.4101
Epoch: [44] Val - TotalT: 23.3 min, Loss: 0.1765
Global IoU: 0.7974
Epoch: [45] Train - TotalT: 23.4 min, BatchT: 0.599s, DataT: 0.334s, Loss: 0.3944
Epoch: [45] Val - TotalT: 23.4 min, Loss: 0.1777
Global IoU: 0.7963
Epoch: [46] Train - TotalT: 23.6 min, BatchT: 0.588s, DataT: 0.323s, Loss: 0.4389
Epoch: [46] Val - TotalT: 23.6 min, Loss: 0.1831
Global IoU: 0.7926
Epoch: [47] Train - TotalT: 23.8 min, BatchT: 0.589s, DataT: 0.323s, Loss: 0.4260
Epoch: [47] Val - TotalT: 23.8 min, Loss: 0.1809
Global IoU: 0.7977
Epoch: [48] Train - TotalT: 24.0 min, BatchT: 0.594s, DataT: 0.329s, Loss: 0.3885
Epoch: [48] Val - TotalT: 24.0 min, Loss: 0.1815
Global IoU: 0.7991
Epoch: [49] Train - TotalT: 24.2 min, BatchT: 0.596s, DataT: 0.330s, Loss: 0.4018
Epoch: [49] Val - TotalT: 24.2 min, Loss: 0.1803
Global IoU: 0.7972
Epoch 00029: reducing learning rate of group 0 to 1.0000e-07.
Epoch: [50] Train - TotalT: 24.4 min, BatchT: 0.578s, DataT: 0.312s, Loss: 0.3902
Epoch: [50] Val - TotalT: 24.4 min, Loss: 0.1805
Global IoU: 0.7978
Epoch: [51] Train - TotalT: 24.6 min, BatchT: 0.572s, DataT: 0.304s, Loss: 0.4277
Epoch: [51] Val - TotalT: 24.6 min, Loss: 0.1815
Global IoU: 0.7987
Epoch: [52] Train - TotalT: 24.8 min, BatchT: 0.580s, DataT: 0.314s, Loss: 0.3747
Epoch: [52] Val - TotalT: 24.8 min, Loss: 0.1821
Global IoU: 0.7994
Epoch: [53] Train - TotalT: 25.0 min, BatchT: 0.546s, DataT: 0.279s, Loss: 0.4018
Epoch: [53] Val - TotalT: 25.0 min, Loss: 0.1774
Global IoU: 0.7998
Epoch: [54] Train - TotalT: 25.2 min, BatchT: 0.604s, DataT: 0.337s, Loss: 0.4325
Epoch: [54] Val - TotalT: 25.2 min, Loss: 0.1876
Global IoU: 0.7976
Epoch: [55] Train - TotalT: 25.4 min, BatchT: 0.589s, DataT: 0.324s, Loss: 0.4000
Epoch: [55] Val - TotalT: 25.4 min, Loss: 0.1826
Global IoU: 0.7936
Epoch: [56] Train - TotalT: 25.5 min, BatchT: 0.596s, DataT: 0.330s, Loss: 0.3834
Epoch: [56] Val - TotalT: 25.6 min, Loss: 0.1807
Global IoU: 0.7958
Epoch 00036: reducing learning rate of group 0 to 1.0000e-08.
Epoch: [57] Train - TotalT: 25.7 min, BatchT: 0.601s, DataT: 0.336s, Loss: 0.3982
Epoch: [57] Val - TotalT: 25.8 min, Loss: 0.1795
Global IoU: 0.7953
Epoch: [58] Train - TotalT: 25.9 min, BatchT: 0.568s, DataT: 0.303s, Loss: 0.4136
Epoch: [58] Val - TotalT: 26.0 min, Loss: 0.1803
Global IoU: 0.7931
Epoch: [59] Train - TotalT: 26.1 min, BatchT: 0.575s, DataT: 0.310s, Loss: 0.3857
Epoch: [59] Val - TotalT: 26.2 min, Loss: 0.1787
Global IoU: 0.7968
Epoch: [60] Train - TotalT: 26.3 min, BatchT: 0.581s, DataT: 0.315s, Loss: 0.3947
Epoch: [60] Val - TotalT: 26.4 min, Loss: 0.1807
Global IoU: 0.7983
Epoch: [61] Train - TotalT: 26.5 min, BatchT: 0.587s, DataT: 0.320s, Loss: 0.3918
Epoch: [61] Val - TotalT: 26.6 min, Loss: 0.1766
Global IoU: 0.8003
Epoch: [62] Train - TotalT: 26.7 min, BatchT: 0.586s, DataT: 0.321s, Loss: 0.4192
Epoch: [62] Val - TotalT: 26.8 min, Loss: 0.1820
Global IoU: 0.7950
Epoch: [63] Train - TotalT: 26.9 min, BatchT: 0.575s, DataT: 0.310s, Loss: 0.4418
Epoch: [63] Val - TotalT: 26.9 min, Loss: 0.1857
Global IoU: 0.7979
Epoch: [64] Train - TotalT: 27.1 min, BatchT: 0.606s, DataT: 0.341s, Loss: 0.3746
Epoch: [64] Val - TotalT: 27.1 min, Loss: 0.1794
Global IoU: 0.7987
Epoch: [65] Train - TotalT: 27.3 min, BatchT: 0.603s, DataT: 0.338s, Loss: 0.4405
Epoch: [65] Val - TotalT: 27.3 min, Loss: 0.1846
Global IoU: 0.7949
Epoch: [66] Train - TotalT: 27.5 min, BatchT: 0.597s, DataT: 0.332s, Loss: 0.4227
Epoch: [66] Val - TotalT: 27.5 min, Loss: 0.1857
Global IoU: 0.7937
Epoch: [67] Train - TotalT: 27.7 min, BatchT: 0.557s, DataT: 0.292s, Loss: 0.4048
Epoch: [67] Val - TotalT: 27.7 min, Loss: 0.1803
Global IoU: 0.7953
Epoch: [68] Train - TotalT: 27.9 min, BatchT: 0.559s, DataT: 0.292s, Loss: 0.4153
Epoch: [68] Val - TotalT: 27.9 min, Loss: 0.1811
Global IoU: 0.7949
Epoch: [69] Train - TotalT: 28.1 min, BatchT: 0.577s, DataT: 0.310s, Loss: 0.4132
Epoch: [69] Val - TotalT: 28.1 min, Loss: 0.1822
Global IoU: 0.7951
Epoch: [70] Train - TotalT: 28.3 min, BatchT: 0.564s, DataT: 0.296s, Loss: 0.4091
Epoch: [70] Val - TotalT: 28.3 min, Loss: 0.1799
Global IoU: 0.7974
Epoch: [71] Train - TotalT: 28.4 min, BatchT: 0.570s, DataT: 0.305s, Loss: 0.3799
Epoch: [71] Val - TotalT: 28.5 min, Loss: 0.1809
Global IoU: 0.7996
Epoch: [72] Train - TotalT: 28.6 min, BatchT: 0.616s, DataT: 0.351s, Loss: 0.3960
Epoch: [72] Val - TotalT: 28.7 min, Loss: 0.1843
Global IoU: 0.7979
Epoch: [73] Train - TotalT: 28.8 min, BatchT: 0.589s, DataT: 0.324s, Loss: 0.4267
Epoch: [73] Val - TotalT: 28.9 min, Loss: 0.1855
Global IoU: 0.7937
Epoch: [74] Train - TotalT: 29.0 min, BatchT: 0.576s, DataT: 0.312s, Loss: 0.3690
Epoch: [74] Val - TotalT: 29.1 min, Loss: 0.1803
Global IoU: 0.7986
Epoch: [75] Train - TotalT: 29.2 min, BatchT: 0.587s, DataT: 0.321s, Loss: 0.4238
Epoch: [75] Val - TotalT: 29.3 min, Loss: 0.1823
Global IoU: 0.7951
Epoch: [76] Train - TotalT: 29.4 min, BatchT: 0.578s, DataT: 0.312s, Loss: 0.4034
Epoch: [76] Val - TotalT: 29.5 min, Loss: 0.1835
Global IoU: 0.7968
Epoch: [77] Train - TotalT: 29.6 min, BatchT: 0.562s, DataT: 0.295s, Loss: 0.3964
Epoch: [77] Val - TotalT: 29.7 min, Loss: 0.1810
Global IoU: 0.7952
Epoch: [78] Train - TotalT: 29.8 min, BatchT: 0.576s, DataT: 0.309s, Loss: 0.4064
Epoch: [78] Val - TotalT: 29.9 min, Loss: 0.1832
Global IoU: 0.7971
Epoch: [79] Train - TotalT: 30.0 min, BatchT: 0.576s, DataT: 0.309s, Loss: 0.4153
Epoch: [79] Val - TotalT: 30.0 min, Loss: 0.1866
Global IoU: 0.7980
Epoch: [80] Train - TotalT: 30.2 min, BatchT: 0.577s, DataT: 0.310s, Loss: 0.3959
Epoch: [80] Val - TotalT: 30.2 min, Loss: 0.1829
Global IoU: 0.7982
Epoch: [81] Train - TotalT: 30.4 min, BatchT: 0.593s, DataT: 0.327s, Loss: 0.4087
Epoch: [81] Val - TotalT: 30.4 min, Loss: 0.1815
Global IoU: 0.7963
Epoch: [82] Train - TotalT: 30.6 min, BatchT: 0.594s, DataT: 0.330s, Loss: 0.4150
Epoch: [82] Val - TotalT: 30.6 min, Loss: 0.1785
Global IoU: 0.7990
Epoch: [83] Train - TotalT: 30.8 min, BatchT: 0.563s, DataT: 0.298s, Loss: 0.4596
Epoch: [83] Val - TotalT: 30.8 min, Loss: 0.1898
Global IoU: 0.7964
Epoch: [84] Train - TotalT: 31.0 min, BatchT: 0.585s, DataT: 0.320s, Loss: 0.4026
Epoch: [84] Val - TotalT: 31.0 min, Loss: 0.1801
Global IoU: 0.8011
Epoch: [85] Train - TotalT: 31.2 min, BatchT: 0.602s, DataT: 0.336s, Loss: 0.4027
Epoch: [85] Val - TotalT: 31.2 min, Loss: 0.1850
Global IoU: 0.7978
Epoch: [86] Train - TotalT: 31.4 min, BatchT: 0.558s, DataT: 0.293s, Loss: 0.4028
Epoch: [86] Val - TotalT: 31.4 min, Loss: 0.1847
Global IoU: 0.7983
Epoch: [87] Train - TotalT: 31.5 min, BatchT: 0.560s, DataT: 0.292s, Loss: 0.4163
Epoch: [87] Val - TotalT: 31.6 min, Loss: 0.1816
Global IoU: 0.7967
Epoch: [88] Train - TotalT: 31.7 min, BatchT: 0.557s, DataT: 0.292s, Loss: 0.4247
Epoch: [88] Val - TotalT: 31.8 min, Loss: 0.1828
Global IoU: 0.7968
Epoch: [89] Train - TotalT: 31.9 min, BatchT: 0.584s, DataT: 0.317s, Loss: 0.4199
Epoch: [89] Val - TotalT: 32.0 min, Loss: 0.1810
Global IoU: 0.7993
Epoch: [90] Train - TotalT: 32.1 min, BatchT: 0.560s, DataT: 0.295s, Loss: 0.3887
Epoch: [90] Val - TotalT: 32.2 min, Loss: 0.1801
Global IoU: 0.7981
Epoch: [91] Train - TotalT: 32.3 min, BatchT: 0.579s, DataT: 0.315s, Loss: 0.3984
Epoch: [91] Val - TotalT: 32.3 min, Loss: 0.1781
Global IoU: 0.7977
Epoch: [92] Train - TotalT: 32.5 min, BatchT: 0.555s, DataT: 0.289s, Loss: 0.4166
Epoch: [92] Val - TotalT: 32.5 min, Loss: 0.1816
Global IoU: 0.7956
Epoch: [93] Train - TotalT: 32.7 min, BatchT: 0.563s, DataT: 0.298s, Loss: 0.4388
Epoch: [93] Val - TotalT: 32.7 min, Loss: 0.1794
Global IoU: 0.7988
Epoch: [94] Train - TotalT: 32.9 min, BatchT: 0.559s, DataT: 0.292s, Loss: 0.4065
Epoch: [94] Val - TotalT: 32.9 min, Loss: 0.1806
Global IoU: 0.7990
Epoch: [95] Train - TotalT: 33.1 min, BatchT: 0.564s, DataT: 0.298s, Loss: 0.3850
Epoch: [95] Val - TotalT: 33.1 min, Loss: 0.1776
Global IoU: 0.7987
Epoch: [96] Train - TotalT: 33.2 min, BatchT: 0.573s, DataT: 0.307s, Loss: 0.3953
Epoch: [96] Val - TotalT: 33.3 min, Loss: 0.1787
Global IoU: 0.7989
Epoch: [97] Train - TotalT: 33.4 min, BatchT: 0.542s, DataT: 0.276s, Loss: 0.4160
Epoch: [97] Val - TotalT: 33.5 min, Loss: 0.1833
Global IoU: 0.7978
Epoch: [98] Train - TotalT: 33.6 min, BatchT: 0.557s, DataT: 0.290s, Loss: 0.4238
Epoch: [98] Val - TotalT: 33.7 min, Loss: 0.1853
Global IoU: 0.7978
Epoch: [99] Train - TotalT: 33.8 min, BatchT: 0.568s, DataT: 0.303s, Loss: 0.3902
Epoch: [99] Val - TotalT: 33.8 min, Loss: 0.1805
Global IoU: 0.7987
Epoch: [100] Train - TotalT: 34.0 min, BatchT: 0.574s, DataT: 0.309s, Loss: 0.4221
Epoch: [100] Val - TotalT: 34.0 min, Loss: 0.1797
Global IoU: 0.7969
Epoch: [101] Train - TotalT: 34.2 min, BatchT: 0.568s, DataT: 0.300s, Loss: 0.3911
Epoch: [101] Val - TotalT: 34.2 min, Loss: 0.1827
Global IoU: 0.7941
Epoch: [102] Train - TotalT: 34.4 min, BatchT: 0.572s, DataT: 0.307s, Loss: 0.4144
Epoch: [102] Val - TotalT: 34.4 min, Loss: 0.1817
Global IoU: 0.7945
Epoch: [103] Train - TotalT: 34.5 min, BatchT: 0.554s, DataT: 0.287s, Loss: 0.3851
Epoch: [103] Val - TotalT: 34.6 min, Loss: 0.1793
Global IoU: 0.7965
Epoch: [104] Train - TotalT: 34.7 min, BatchT: 0.565s, DataT: 0.300s, Loss: 0.4572
Epoch: [104] Val - TotalT: 34.8 min, Loss: 0.1836
Global IoU: 0.7963
Epoch: [105] Train - TotalT: 34.9 min, BatchT: 0.568s, DataT: 0.302s, Loss: 0.3873
Epoch: [105] Val - TotalT: 35.0 min, Loss: 0.1842
Global IoU: 0.7974
Epoch: [106] Train - TotalT: 35.1 min, BatchT: 0.548s, DataT: 0.282s, Loss: 0.3954
Epoch: [106] Val - TotalT: 35.2 min, Loss: 0.1803
Global IoU: 0.7999
Epoch: [107] Train - TotalT: 35.3 min, BatchT: 0.561s, DataT: 0.295s, Loss: 0.4308
Epoch: [107] Val - TotalT: 35.3 min, Loss: 0.1861
Global IoU: 0.7975
Epoch: [108] Train - TotalT: 35.5 min, BatchT: 0.568s, DataT: 0.302s, Loss: 0.3932
Epoch: [108] Val - TotalT: 35.5 min, Loss: 0.1829
Global IoU: 0.7986
Epoch: [109] Train - TotalT: 35.7 min, BatchT: 0.553s, DataT: 0.286s, Loss: 0.4078
Epoch: [109] Val - TotalT: 35.7 min, Loss: 0.1814
Global IoU: 0.7986
Epoch: [110] Train - TotalT: 35.9 min, BatchT: 0.576s, DataT: 0.311s, Loss: 0.4301
Epoch: [110] Val - TotalT: 35.9 min, Loss: 0.1827
Global IoU: 0.7934
Epoch: [111] Train - TotalT: 36.0 min, BatchT: 0.558s, DataT: 0.293s, Loss: 0.4032
Epoch: [111] Val - TotalT: 36.1 min, Loss: 0.1824
Global IoU: 0.8007
Epoch: [112] Train - TotalT: 36.2 min, BatchT: 0.565s, DataT: 0.301s, Loss: 0.4245
Epoch: [112] Val - TotalT: 36.3 min, Loss: 0.1820
Global IoU: 0.7996
Epoch: [113] Train - TotalT: 36.4 min, BatchT: 0.574s, DataT: 0.309s, Loss: 0.4253
Epoch: [113] Val - TotalT: 36.5 min, Loss: 0.1822
Global IoU: 0.7993
Epoch: [114] Train - TotalT: 36.6 min, BatchT: 0.576s, DataT: 0.311s, Loss: 0.3950
Epoch: [114] Val - TotalT: 36.7 min, Loss: 0.1825
Global IoU: 0.7962
Epoch: [115] Train - TotalT: 36.8 min, BatchT: 0.572s, DataT: 0.307s, Loss: 0.4351
Epoch: [115] Val - TotalT: 36.8 min, Loss: 0.1826
Global IoU: 0.7923
Early Stopping
-\|/-\|Best IOU: 0.8010584498948777 at Epoch: 84
----------------------------------------
Training Completed:
Total Training Time: 2275.0304341316223 seconds
