{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "# flake8: noqa: E501\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    Adapted from https://github.com/pytorch/examples/blob/master/imagenet/main.py    # noqa: E501\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    if device.startswith('npu'):\n",
    "        return {k: v.to(device, non_blocking=True) for k, v in data.items()}\n",
    "    else:\n",
    "        Warning(\"NPU Device is not supported\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def print_epoch_stats(phase,\n",
    "                      epoch,\n",
    "                      loss_meter,\n",
    "                      batch_time,\n",
    "                      data_time,\n",
    "                      start_time,\n",
    "                      iou=None):\n",
    "    if iou:\n",
    "        print(\n",
    "            f\"Epoch: [{epoch}] {phase} - TotalT: {(time.time() - start_time) / 60:.1f} min, \"\n",
    "            f\"Loss: {loss_meter.avg:.4f}, Global IoU: {iou:.4f}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Epoch: [{epoch}] {phase} - TotalT: {(time.time() - start_time) / 60:.1f} min, \"\n",
    "            f\"BatchT: {batch_time.avg:.3f}s, DataT: {data_time.avg:.3f}s, Loss: {loss_meter.avg:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def save_model(epoch, iou, model, optimizer, experiment_name, log_path,\n",
    "               best_metric, best_metric_epoch):\n",
    "    save_dict = {\n",
    "        \"model_name\": experiment_name,\n",
    "        \"epoch_num\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optim_state_dict\": optimizer.state_dict(),\n",
    "        \"iou\": iou\n",
    "    }\n",
    "    old_model_path = glob.glob(f\"{log_path}/best_iou*\")\n",
    "    if old_model_path:\n",
    "        os.remove(old_model_path[0])\n",
    "    torch.save(save_dict, f\"{log_path}/best_iou_{epoch}_{iou:.4f}.pt\")\n",
    "\n",
    "    if iou > best_metric:\n",
    "        best_metric, best_metric_epoch = iou, epoch\n",
    "\n",
    "    return best_metric, best_metric_epoch\n",
    "\n",
    "\n",
    "def create_data_loader(dataset, batch_size, shuffle, num_workers, pin_memory):\n",
    "    return torch.utils.data.DataLoader(dataset,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=shuffle,\n",
    "                                       num_workers=num_workers,\n",
    "                                       pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "def generate_paths(base_path, pattern, replacements):\n",
    "    paths = sorted(glob.glob(f\"{base_path}/{pattern}\"))\n",
    "    return [\n",
    "        list(map(lambda r: path.replace(*r), replacements)) for path in paths\n",
    "    ]\n",
    "\n",
    "\n",
    "def split_data(paths, train_perc, val_perc):\n",
    "    np.random.seed(17)\n",
    "    np.random.shuffle(paths)\n",
    "    n = len(paths)\n",
    "    return {\n",
    "        \"train\": paths[:int(train_perc * n)],\n",
    "        \"val\": paths[int(train_perc * n):int((train_perc + val_perc) * n)],\n",
    "        \"test\": paths[int((train_perc + val_perc) * n):]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "# flake8: noqa: E501\n",
    "\n",
    "\n",
    "def visualize_s2_img(s2_channel_paths):\n",
    "    \"\"\"\n",
    "    Calculates and returns a 'SWIR' S2 false color composite ready for visualization.\n",
    "\n",
    "    Args:\n",
    "        s2_channel_paths (list of str): Paths to the ['B12', 'B7', 'B4'] bands of a S2 image.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Image (H, W, 3) ready for visualization with e.g. plt.imshow(..)\n",
    "    \"\"\"\n",
    "    img = []\n",
    "    for path in s2_channel_paths:\n",
    "        img.append(tifffile.imread(path))\n",
    "    img = np.stack(img, axis=-1)\n",
    "    return scale_S1_S2_img(img, sentinel=2)\n",
    "\n",
    "\n",
    "def visualize_s1_img(path_vv, path_vh):\n",
    "    \"\"\"\n",
    "    Calculates and returns a S1 false color composite ready for visualization.\n",
    "\n",
    "    Args:\n",
    "        path_vv (str): Path to the VV band.\n",
    "        path_vh (str): Path to the VH band.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Image (H, W, 3) ready for visualization with e.g. plt.imshow(..)\n",
    "    \"\"\"\n",
    "    s1_img = np.stack((tifffile.imread(path_vv), tifffile.imread(path_vh)),\n",
    "                      axis=-1)\n",
    "    img = np.zeros((s1_img.shape[0], s1_img.shape[1], 3), dtype=np.float32)\n",
    "    img[:, :, :2] = s1_img.copy()\n",
    "    img[:, :, 2] = s1_img[:, :, 0] / s1_img[:, :, 1]\n",
    "    s1_img = np.nan_to_num(s1_img)\n",
    "    return scale_S1_S2_img(img, sentinel=1)\n",
    "\n",
    "\n",
    "def scale_S1_S2_img(matrix, sentinel=2):\n",
    "    \"\"\"\n",
    "    Returns a scaled (H,W,D) image which is more easily visually inspectable. Image is linearly scaled between\n",
    "    min and max_value of by channel.\n",
    "    Args:\n",
    "        matrix (np.array): (H,W,D) image to be scaled\n",
    "        sentinel (int, optional): Sentinel 1 or Sentinel 2 image? Determines the min and max values for scalin, defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Image (H, W, 3) ready for visualization with e.g. plt.imshow(..)\n",
    "    \"\"\"\n",
    "    w, h, d = matrix.shape\n",
    "    min_values = np.array([100, 100, 100]) if sentinel == 2 else np.array(\n",
    "        [-23, -28, 0.2])\n",
    "    max_values = np.array([3500, 3500, 3500]) if sentinel == 2 else np.array(\n",
    "        [0, -5, 1])\n",
    "\n",
    "    matrix = np.reshape(matrix, [w * h, d]).astype(np.float64)\n",
    "    matrix = (matrix - min_values[None, :]) / (max_values[None, :] -\n",
    "                                               min_values[None, :])\n",
    "    matrix = np.reshape(matrix, [w, h, d])\n",
    "\n",
    "    matrix = matrix.clip(0, 1)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def mask_to_img(label, color_dict):\n",
    "    \"\"\"Recodes a (H,W) mask to a (H,W,3) RGB image according to color_dict\"\"\"\n",
    "    mutually_exclusive = np.zeros(label.shape + (3, ), dtype=np.uint8)\n",
    "    for key in range(1, len(color_dict.keys()) + 1):\n",
    "        mutually_exclusive[label == key] = color_dict[key]\n",
    "    return mutually_exclusive\n",
    "\n",
    "\n",
    "class Sentinel1_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_paths,\n",
    "        mask_paths,\n",
    "        transforms=None,\n",
    "        min_normalize=-77,\n",
    "        max_normalize=26,\n",
    "    ):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms\n",
    "        self.min_normalize = min_normalize\n",
    "        self.max_normalize = max_normalize\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load in image\n",
    "        arr_x = []\n",
    "        for path in self.img_paths[idx]:\n",
    "            arr_x.append(tifffile.imread(path))\n",
    "        arr_x = np.stack(arr_x, axis=-1)\n",
    "        # Min-Max Normalization\n",
    "        arr_x = np.clip(arr_x, self.min_normalize, self.max_normalize)\n",
    "        arr_x = (arr_x - self.min_normalize) / (self.max_normalize -\n",
    "                                                self.min_normalize)\n",
    "\n",
    "        sample = {\"image\": arr_x}\n",
    "\n",
    "        # Load in label mask\n",
    "        sample[\"mask\"] = tifffile.imread(self.mask_paths[idx])\n",
    "\n",
    "        # Apply Data Augmentation\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=sample[\"image\"],\n",
    "                                     mask=sample[\"mask\"])\n",
    "        if sample[\"image\"].shape[-1] < 20:\n",
    "            sample[\"image\"] = sample[\"image\"].transpose((2, 0, 1))\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def visualize(self, how_many=1, show_specific_index=None):\n",
    "        for _ in range(how_many):\n",
    "            rand_int = np.random.randint(len(self.img_paths))\n",
    "            if show_specific_index is not None:\n",
    "                rand_int = show_specific_index\n",
    "            print(self.img_paths[rand_int][0])\n",
    "            f, axarr = plt.subplots(1, 3, figsize=(30, 9))\n",
    "            axarr[0].imshow(\n",
    "                visualize_s1_img(self.img_paths[rand_int][0],\n",
    "                                 self.img_paths[rand_int][1]))\n",
    "            sample = self.__getitem__(rand_int)\n",
    "\n",
    "            img = sample[\"image\"]\n",
    "            axarr[0].set_title(\"FCC of original S1 image\", fontsize=15)  # noqa\n",
    "            axarr[1].imshow(img[0])  # Just visualize the VV band here\n",
    "            axarr[1].set_title(\n",
    "                f\"VV band returned from the dataset, Min: {img.min():.4f}, Max: {img.max():.4f}\",\n",
    "                fontsize=15)\n",
    "            if \"mask\" in sample.keys():\n",
    "                axarr[2].set_title(\n",
    "                    f\"Corresponding water mask: {(sample['mask'] == 1).sum()} px\",\n",
    "                    fontsize=15)\n",
    "                mask = mask_to_img(sample[\"mask\"], {1: (0, 0, 255)})\n",
    "                axarr[2].imshow(mask)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class XEDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.5, EPS=1e-7):\n",
    "        super().__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.alpha = alpha\n",
    "        self.EPS = EPS\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        xe_loss = self.cross_entropy(preds, targets)\n",
    "        dice_loss = self.calculate_dice_loss(preds, targets)\n",
    "        return self.alpha * xe_loss + (1 - self.alpha) * dice_loss\n",
    "\n",
    "    def calculate_dice_loss(self, preds, targets):\n",
    "        targets = targets.float()\n",
    "        preds = torch.softmax(preds, dim=1)[:, 1]\n",
    "        intersection = torch.sum(preds * targets)\n",
    "        union = torch.sum(preds + targets)\n",
    "        return 1 - (2.0 * intersection) / (union + self.EPS)\n",
    "\n",
    "\n",
    "# Metric Calculation\n",
    "def tp_fp_fn(preds, targets):\n",
    "    tp = torch.sum(preds * targets)\n",
    "    fp = torch.sum(preds) - tp\n",
    "    fn = torch.sum(targets) - tp\n",
    "    return tp.item(), fp.item(), fn.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_epochs(model, train_loader, val_loader, optimizer, loss_func,\n",
    "                 experiment_name, log_path, scheduler, N_EPOCHS,\n",
    "                 EARLY_STOP_THRESHOLD, EARLY_STOP_PATIENCE, DEVICE, EPS):\n",
    "    best_metric, best_metric_epoch = 0, 0\n",
    "    early_stop_counter, best_val_early_stopping_metric = 0, 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for curr_epoch_num in range(1, N_EPOCHS + 1):\n",
    "        # 训练\n",
    "        model.train()\n",
    "        train_loss, batch_time, data_time = AverageMeter(), AverageMeter(\n",
    "        ), AverageMeter()\n",
    "        end = time.time()\n",
    "\n",
    "        for data in train_loader:\n",
    "            data_time.update(time.time() - end)\n",
    "            data = to_device(data, DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(data[\"image\"])\n",
    "            loss = loss_func(preds, data[\"mask\"].long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.update(loss.item(), data[\"image\"].size(0))\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "        print_epoch_stats('Train', curr_epoch_num, train_loss, batch_time,\n",
    "                          data_time, start_time)\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss, tps, fps, fns = AverageMeter(), 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = to_device(data, DEVICE)\n",
    "                preds = model(data[\"image\"])\n",
    "                loss = loss_func(preds, data[\"mask\"].long())\n",
    "                val_loss.update(loss.item(), data[\"image\"].size(0))\n",
    "                preds_binary = (torch.softmax(preds, dim=1)[:, 1] > 0.5).long()\n",
    "                tp, fp, fn = tp_fp_fn(preds_binary, data[\"mask\"])\n",
    "                tps += tp\n",
    "                fps += fp\n",
    "                fns += fn\n",
    "\n",
    "        iou_global = tps / (tps + fps + fns + EPS)\n",
    "        print_epoch_stats('Val', curr_epoch_num, val_loss, batch_time,\n",
    "                          data_time, start_time, iou_global)\n",
    "\n",
    "        # 保存Scheduler和Model\n",
    "        if curr_epoch_num > EARLY_STOP_THRESHOLD:\n",
    "            scheduler.step(iou_global)\n",
    "        if iou_global > best_metric:\n",
    "            best_metric, best_metric_epoch = save_model(\n",
    "                curr_epoch_num, iou_global, model, optimizer, experiment_name,\n",
    "                log_path, best_metric, best_metric_epoch)\n",
    "        if iou_global < best_val_early_stopping_metric:\n",
    "            early_stop_counter += 1\n",
    "        else:\n",
    "            best_val_early_stopping_metric, early_stop_counter = iou_global, 0\n",
    "        if early_stop_counter > EARLY_STOP_PATIENCE:\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "    # 返回有用的信息\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"scheduler\": scheduler,\n",
    "        \"best_metric\": best_metric,\n",
    "        \"best_metric_epoch\": best_metric_epoch,\n",
    "        \"total_epochs\": curr_epoch_num,\n",
    "        \"training_time\": time.time() - start_time\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "class FloodwaterSegmentationModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 encoder_name=\"resnet34\",\n",
    "                 encoder_weights=\"imagenet\",\n",
    "                 in_channels=2,\n",
    "                 classes=2):\n",
    "        \"\"\"\n",
    "        初始化 FloodwaterSegmentationModel 类。\n",
    "\n",
    "        Args:\n",
    "            encoder_name (str): 使用的编码器名称。默认为 'resnet34'。\n",
    "            encoder_weights (str): 编码器的预训练权重。默认为 'imagenet'。\n",
    "            in_channels (int): 输入通道数。对于 Sentinel-1 数据，默认为 2（VV 和 VH）。\n",
    "            classes (int): 输出类别数。对于二分类问题，默认为 2。\n",
    "        \"\"\"\n",
    "        super(FloodwaterSegmentationModel, self).__init__()\n",
    "        self.model = smp.Unet(encoder_name=encoder_name,\n",
    "                              encoder_weights=encoder_weights,\n",
    "                              in_channels=in_channels,\n",
    "                              classes=classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        定义模型的前向传播。\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入数据。\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 模型的输出。\n",
    "        \"\"\"\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_npu  # noqa:F401\n",
    "import torch\n",
    "import albumentations\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import sys\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "import time\n",
    "# flake8: noqa: E402\n",
    "\n",
    "\n",
    "#\n",
    "BASE_PATH = \"/home/HW/Pein/Floodwater/dataset\"\n",
    "TRAIN_PERCENTAGE = 0.1\n",
    "VAL_PERCENTAGE = 0.1\n",
    "TEST_PERCENTAGE = round(1 - TRAIN_PERCENTAGE - VAL_PERCENTAGE, 2)\n",
    "MIN_NORMALIZE = -77\n",
    "MAX_NORMALIZE = 26\n",
    "TRAIN_CROP_SIZE = 256\n",
    "\n",
    "label_replacements = [(\"LabelWater.tif\", \"LabelWater.tif\")]\n",
    "image_replacements = [(\"LabelWater.tif\", \"VV.tif\"),\n",
    "                      (\"LabelWater.tif\", \"VH.tif\")]\n",
    "\n",
    "label_paths = generate_paths(BASE_PATH, \"chips/*/s1/*/LabelWater.tif\",\n",
    "                             label_replacements)\n",
    "image_paths = generate_paths(BASE_PATH, \"chips/*/s1/*/LabelWater.tif\",\n",
    "                             image_replacements)\n",
    "\n",
    "label_splits = split_data(label_paths, TRAIN_PERCENTAGE, VAL_PERCENTAGE)\n",
    "image_splits = split_data(image_paths, TRAIN_PERCENTAGE, VAL_PERCENTAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强\n",
    "train_transforms = albumentations.Compose([\n",
    "    albumentations.RandomCrop(TRAIN_CROP_SIZE, TRAIN_CROP_SIZE),\n",
    "    albumentations.RandomRotate90(),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.VerticalFlip()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sentinel1_Dataset初始化\n",
    "train_dataset = Sentinel1_Dataset(image_splits['train'],\n",
    "                                  label_splits['train'],\n",
    "                                  transforms=train_transforms,\n",
    "                                  min_normalize=MIN_NORMALIZE,\n",
    "                                  max_normalize=MAX_NORMALIZE)\n",
    "val_dataset = Sentinel1_Dataset(image_splits['val'],\n",
    "                                label_splits['val'],\n",
    "                                transforms=None,\n",
    "                                min_normalize=MIN_NORMALIZE,\n",
    "                                max_normalize=MAX_NORMALIZE)\n",
    "test_dataset = Sentinel1_Dataset(image_splits['test'],\n",
    "                                 label_splits['test'],\n",
    "                                 transforms=None,\n",
    "                                 min_normalize=MIN_NORMALIZE,\n",
    "                                 max_normalize=MAX_NORMALIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Input shape:(2，512，512). Cropped to (2，256，256) for training. 2 channels represents VH and VV.\n",
    "### Original Output shape:(512，512). Cropped to (256，256) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 dimensions: (2, 512, 512)\n",
      "Sample 0 label dimensions: (512, 512)\n",
      "ratio is 1.0\n",
      "ratio is 0.523\n",
      "ratio is 0.008\n",
      "ratio is 0.107\n",
      "ratio is 0.0\n",
      "ratio is 0.023\n",
      "ratio is 0.113\n",
      "ratio is 0.851\n",
      "ratio is 0.994\n",
      "ratio is 0.264\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    sample = train_dataset[i]\n",
    "    image = sample[\"image\"]\n",
    "    label = sample[\"mask\"]\n",
    "    dim = label.shape[0]\n",
    "    if i == 0:\n",
    "        print(f\"Sample {i} dimensions: {image.shape}\")\n",
    "        print(f\"Sample {i} label dimensions: {label.shape}\")\n",
    "    print(f'ratio is {np.round( np.count_nonzero(label) / (dim**2),3)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 常量\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = False\n",
    "BATCH_SIZE = 64\n",
    "EPS = 1e-7\n",
    "EXPERIMENT_NAME = \"Exp1_res34\"\n",
    "BACKBONE = \"resnet34\"\n",
    "PATIENCE = 5\n",
    "N_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-2\n",
    "LOG_PATH = f\"/home/HW/Pein/Floodwater/trained_models/{EXPERIMENT_NAME}\"\n",
    "os.makedirs(LOG_PATH, exist_ok=True)\n",
    "\n",
    "EARLY_STOP_THRESHOLD = 5\n",
    "EARLY_STOP_PATIENCE = PATIENCE * 5\n",
    "\n",
    "DEVICE = 'npu:7' if torch.npu.is_available() else 'cpu'\n",
    "if torch.npu.is_available() and DEVICE.startswith('npu'):\n",
    "    print(f'Using NPU: {DEVICE} ...')\n",
    "else:\n",
    "    print('Using CPU ...')\n",
    "\n",
    "\n",
    "TRAIN_PERCENTAGE = 0.7\n",
    "VAL_PERCENTAGE = 0.1\n",
    "TEST_PERCENTAGE = round(1 - TRAIN_PERCENTAGE - VAL_PERCENTAGE, 2)\n",
    "# 打印基本信息\n",
    "print(f\"\"\"\n",
    "TRAIN_PERCENTAGE = {TRAIN_PERCENTAGE}\n",
    "VAL_PERCENTAGE = {VAL_PERCENTAGE}\n",
    "TEST_PERCENTAGE = {TEST_PERCENTAGE}\n",
    "NUM_WORKERS = {NUM_WORKERS}\n",
    "PIN_MEMORY = {PIN_MEMORY}\n",
    "BATCH_SIZE = {BATCH_SIZE}\n",
    "EPS = {EPS}\n",
    "EXPERIMENT_NAME = '{EXPERIMENT_NAME}'\n",
    "BACKBONE = '{BACKBONE}'\n",
    "PATIENCE = {PATIENCE}\n",
    "N_EPOCHS = {N_EPOCHS}\n",
    "LEARNING_RATE = {LEARNING_RATE}\n",
    "EARLY_STOP_THRESHOLD = {EARLY_STOP_THRESHOLD}\n",
    "EARLY_STOP_PATIENCE = {EARLY_STOP_PATIENCE}\n",
    "\"\"\")\n",
    "\n",
    "# 加载训练集、验证集和测试集\n",
    "train_loader = create_data_loader(train_dataset,\n",
    "                                  BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=NUM_WORKERS,\n",
    "                                  pin_memory=PIN_MEMORY)\n",
    "val_loader = create_data_loader(val_dataset,\n",
    "                                BATCH_SIZE,\n",
    "                                shuffle=False,\n",
    "                                num_workers=NUM_WORKERS,\n",
    "                                pin_memory=PIN_MEMORY)\n",
    "test_loader = create_data_loader(test_dataset,\n",
    "                                 BATCH_SIZE,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=NUM_WORKERS,\n",
    "                                 pin_memory=PIN_MEMORY)\n",
    "\n",
    "# 模型初始化\n",
    "model = smp.Unet(encoder_name=BACKBONE,\n",
    "                 encoder_weights=\"imagenet\",\n",
    "                 in_channels=2,\n",
    "                 classes=2).to(DEVICE)\n",
    "\n",
    "loss_func = XEDiceLoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode=\"max\",\n",
    "                                                       factor=0.5,\n",
    "                                                       patience=PATIENCE,\n",
    "                                                       verbose=True)\n",
    "# 训练指标初始化\n",
    "best_metric, best_metric_epoch = 0, 0\n",
    "early_stop_counter, best_val_early_stopping_metric = 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 开始训练\n",
    "train_result = train_epochs(model, train_loader, val_loader, optimizer,\n",
    "                            loss_func, EXPERIMENT_NAME, LOG_PATH, scheduler,\n",
    "                            N_EPOCHS, EARLY_STOP_THRESHOLD,\n",
    "                            EARLY_STOP_PATIENCE, DEVICE, EPS)\n",
    "\n",
    "# 打印或处理返回的信息\n",
    "print(\"Training Completed:\")\n",
    "print(\n",
    "    f\"Best IOU: {train_result['best_metric']} at Epoch: {train_result['best_metric_epoch']}\"\n",
    ")\n",
    "print(f\"Total Training Time: {train_result['training_time']} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
